{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77aa7427",
   "metadata": {},
   "source": [
    "# NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3c07ed",
   "metadata": {},
   "source": [
    "### In this part we train our machine learning algorithm to recognize positive and negative sentiments:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7f4104",
   "metadata": {},
   "source": [
    "https://www.datacamp.com/community/tutorials/text-analytics-beginners-nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac54c796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import random as random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32157cae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @ScottWalker: Didn't catch the full #GOPdeb...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @RobGeorge: That Carly Fiorina is trending ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @DanScavino: #GOPDebate w/ @realDonaldTrump...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RT @GregAbbott_TX: @TedCruz: \"On my first day ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RT @warriorwoman91: I liked her and was happy ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment\n",
       "1  RT @ScottWalker: Didn't catch the full #GOPdeb...  Positive\n",
       "3  RT @RobGeorge: That Carly Fiorina is trending ...  Positive\n",
       "4  RT @DanScavino: #GOPDebate w/ @realDonaldTrump...  Positive\n",
       "5  RT @GregAbbott_TX: @TedCruz: \"On my first day ...  Positive\n",
       "6  RT @warriorwoman91: I liked her and was happy ...  Negative"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training data\n",
    "data = pd.read_csv('Sentiment.csv')\n",
    "data = data[['text', 'sentiment']]\n",
    "data = data[data.sentiment != \"Neutral\"]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3702eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative Sentiment count: 8493\n",
      "Positive Sentiment count: 2236\n"
     ]
    }
   ],
   "source": [
    "# imbalanced dataset\n",
    "print('Negative Sentiment count:', len(data[data['sentiment']=='Negative']))\n",
    "print('Positive Sentiment count:',len(data[data['sentiment']=='Positive']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40bfcf83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative Sentiment count: 2236\n",
      "Positive Sentiment count: 2236\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In the @AP factcheck of the #GOPDebate Jeb Bus...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"I'll be my best to do that\" #GOPDebates</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Loved the exasperated look on Jeb's face durin...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @RavingRaver: My response when @megynkelly ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I nominate @FoxNews for the \"Best Comedy Speci...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment\n",
       "0  In the @AP factcheck of the #GOPDebate Jeb Bus...  Negative\n",
       "1           \"I'll be my best to do that\" #GOPDebates  Positive\n",
       "2  Loved the exasperated look on Jeb's face durin...  Negative\n",
       "3  RT @RavingRaver: My response when @megynkelly ...  Negative\n",
       "4  I nominate @FoxNews for the \"Best Comedy Speci...  Positive"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# undersample\n",
    "positive_df = data[data.sentiment != \"Negative\"]\n",
    "negative_df = data[data.sentiment == \"Negative\"]\n",
    "\n",
    "negative_df = negative_df[:len(positive_df)]\n",
    "\n",
    "print('Negative Sentiment count:', len(negative_df))\n",
    "print('Positive Sentiment count:', len(positive_df))\n",
    "\n",
    "# concat the balanced data\n",
    "balanced_data = pd.concat([negative_df, positive_df])\n",
    "balanced_data = balanced_data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "balanced_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26264c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer to remove unwanted elements from out data like symbols and numbers\n",
    "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
    "\n",
    "# create a sparse matrix (BoW)\n",
    "tf=TfidfVectorizer(lowercase=True,stop_words='english',ngram_range = (1,1),tokenizer = token.tokenize)\n",
    "text_tf= tf.fit_transform(balanced_data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb2967b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(text_tf, balanced_data['sentiment'], test_size=0.1, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30c8fd96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB Classifier Accuracy: 0.8080357142857143\n"
     ]
    }
   ],
   "source": [
    "# classify\n",
    "\n",
    "clf = MultinomialNB(alpha=0.1).fit(X_train, y_train)\n",
    "predicted= clf.predict(X_test)\n",
    "\n",
    "print(\"MultinomialNB Classifier Accuracy:\",metrics.accuracy_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bf2f283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Negative'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test for the first element\n",
    "text_tf_2 = tf.fit_transform(balanced_data['text'])\n",
    "clf.predict(text_tf_2)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924e7830",
   "metadata": {},
   "source": [
    "### Here, we input our own data, we clean it and we classify each tweet as positive or negative:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53c0e74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('depression.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c53507b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "### data cleaning ###\n",
    "def remove_links(tweet):\n",
    "    '''Takes a string and removes web links from it'''\n",
    "    tweet = re.sub(r'http\\S+', '', tweet) # remove http links\n",
    "    tweet = re.sub(r'bit.ly/\\S+', '', tweet) # rempve bitly links\n",
    "    tweet = tweet.strip('[link]') # remove [links]\n",
    "    return tweet\n",
    "\n",
    "def remove_users(tweet):\n",
    "    '''Takes a string and removes retweet and @user information'''\n",
    "    tweet = re.sub('(RT\\s@[A-Za-z]+[A-Za-z0-9-_]+)', '', tweet) # remove retweet\n",
    "    tweet = re.sub('(@[A-Za-z]+[A-Za-z0-9-_]+)', '', tweet) # remove tweeted at\n",
    "    return tweet\n",
    "\n",
    "my_stopwords = nltk.corpus.stopwords.words('english')\n",
    "word_rooter = nltk.stem.snowball.PorterStemmer(ignore_stopwords=False).stem\n",
    "my_punctuation = '!\"$%&\\'()*+,-./:;<=>?[\\\\]^_`{|}~‚Ä¢@'\n",
    "\n",
    "# cleaning master function\n",
    "def clean_tweet(tweet, bigrams=False):\n",
    "    tweet = remove_users(tweet)\n",
    "    tweet = remove_links(tweet)\n",
    "    tweet = tweet.lower() # lower case\n",
    "    tweet = re.sub('['+my_punctuation + ']+', ' ', tweet) # strip punctuation\n",
    "    tweet = re.sub('\\s+', ' ', tweet) #remove double spacing\n",
    "    tweet = re.sub('([0-9]+)', '', tweet) # remove numbers\n",
    "    tweet_token_list = [word for word in tweet.split(' ')\n",
    "                            if word not in my_stopwords] # remove stopwords\n",
    "\n",
    "    tweet_token_list = [word_rooter(word) if '#' not in word else word\n",
    "                        for word in tweet_token_list] # apply word rooter\n",
    "    if bigrams:\n",
    "        tweet_token_list = tweet_token_list+[tweet_token_list[i]+'_'+tweet_token_list[i+1]\n",
    "                                            for i in range(len(tweet_token_list)-1)]\n",
    "    tweet = ' '.join(tweet_token_list)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "585d565e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "data['clean_tweet'] = data.text.apply(clean_tweet, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ed952d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    extend abstract submiss deadlin today‚ùó add fin...\n",
       "1    üåüthi fall intent spend time natur ‚ñ™Ô∏èit help de...\n",
       "2    proud welcom stephani kunkel motiv champ famil...\n",
       "3    much energi put keep appear ‚Å† se jump ‚Å† #trave...\n",
       "4    know treat season affect disord #seasonalaffec...\n",
       "Name: clean_tweet, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = data['clean_tweet']\n",
    "tweets.dropna(how='all')\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97ae4af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the actual data\n",
    "tweet_tf= tf.transform(tweets.values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c9ce34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classify\n",
    "sentiment = []\n",
    "for i in range(len(list(tweets))):\n",
    "    s = clf.predict(tweet_tf)[i]\n",
    "    sentiment.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82845227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add sentiment to the dataset\n",
    "data['sentiment'] = sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f5a01b",
   "metadata": {},
   "source": [
    "\n",
    "### Sentiment Analysis done!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a737abd",
   "metadata": {},
   "source": [
    "### Let's test a random tweet, namely 25:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81afb529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We are facing unprecedented circumstances that can cause anyone anxiety. Add parenthood or pregnancy into the mix, and that level of anxiety could quickly escalate. Learn more about perinatal mood and anxiety disorders. #pmad #depression #anxiety\\r\\r\\nhttps://t.co/oi5NPNTlQl'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.text[25]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf5b5c3",
   "metadata": {},
   "source": [
    "### The algorithm outputs 'negative', which seems right:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5cef9531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Negative'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sentiment[25]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b1117a",
   "metadata": {},
   "source": [
    "### The algorithm has classified 4,658 tweets as 'Positive' and 12,075 'Negative'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e0d7db",
   "metadata": {},
   "source": [
    "That means roughly 30% of the tweets about depression on Twitter are positive, and 70% are of negative sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e61247c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4658"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[data['sentiment']=='Positive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6dfdfd50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12075"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[data['sentiment']=='Negative'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

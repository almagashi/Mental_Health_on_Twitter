{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87252ba8",
   "metadata": {},
   "source": [
    "**Import libraries and packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05810721",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.decomposition import NMF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7347fa74",
   "metadata": {},
   "source": [
    "**Read the data from the file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4059dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### read data ###\n",
    "data = pd.read_csv('adhd.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b427ce",
   "metadata": {},
   "source": [
    "One example of how a tweet looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e5063df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why women may wait decades for an #ADHD diagnosis https://t.co/nu3mAQfVU8'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.text[4444]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b1f1ef",
   "metadata": {},
   "source": [
    "A sneak-peek at the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f48282d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>user_ID</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>user_location</th>\n",
       "      <th>user_description</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1365319367676878849</td>\n",
       "      <td>52</td>\n",
       "      <td>Sheffield, England</td>\n",
       "      <td>‚ù§Sal / UK\\r\\r\\nüß°Player of games, Master of non...</td>\n",
       "      <td>2021-10-27 12:40:38</td>\n",
       "      <td>Saw GP today and we went through stuff and I t...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>53638786</td>\n",
       "      <td>1667</td>\n",
       "      <td>UK</td>\n",
       "      <td>27y/o nonbinary creator. They/Them. disabled. ...</td>\n",
       "      <td>2021-10-27 12:40:00</td>\n",
       "      <td>My ADHD Graveyard | Officially Diagnosed and A...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1329360990765539329</td>\n",
       "      <td>12</td>\n",
       "      <td>England, United Kingdom</td>\n",
       "      <td>38. A diagnosis referral is hard in the UK. Se...</td>\n",
       "      <td>2021-10-27 12:37:21</td>\n",
       "      <td>Have there been any studies of adults or child...</td>\n",
       "      <td>['askADHD', 'ADHD']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1242603133450293261</td>\n",
       "      <td>8</td>\n",
       "      <td>West Hempstead, NY</td>\n",
       "      <td>OrganizeU4Life is making an impact on the live...</td>\n",
       "      <td>2021-10-27 12:35:03</td>\n",
       "      <td>Environmental factors don‚Äôt directly cause ADH...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1429032961744281602</td>\n",
       "      <td>48</td>\n",
       "      <td>Espa√±a</td>\n",
       "      <td>üîû. Mainly NSFW. He/Him. 28. Gay, Single and Lo...</td>\n",
       "      <td>2021-10-27 12:33:08</td>\n",
       "      <td>Here in Spain we celebrate the national day of...</td>\n",
       "      <td>['ADHD']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0              user_ID  followers_count            user_location  \\\n",
       "0           0  1365319367676878849               52       Sheffield, England   \n",
       "1           1             53638786             1667                       UK   \n",
       "2           2  1329360990765539329               12  England, United Kingdom   \n",
       "3           3  1242603133450293261                8       West Hempstead, NY   \n",
       "4           4  1429032961744281602               48                   Espa√±a   \n",
       "\n",
       "                                    user_description                 date  \\\n",
       "0  ‚ù§Sal / UK\\r\\r\\nüß°Player of games, Master of non...  2021-10-27 12:40:38   \n",
       "1  27y/o nonbinary creator. They/Them. disabled. ...  2021-10-27 12:40:00   \n",
       "2  38. A diagnosis referral is hard in the UK. Se...  2021-10-27 12:37:21   \n",
       "3  OrganizeU4Life is making an impact on the live...  2021-10-27 12:35:03   \n",
       "4  üîû. Mainly NSFW. He/Him. 28. Gay, Single and Lo...  2021-10-27 12:33:08   \n",
       "\n",
       "                                                text             hashtags  \n",
       "0  Saw GP today and we went through stuff and I t...                  NaN  \n",
       "1  My ADHD Graveyard | Officially Diagnosed and A...                  NaN  \n",
       "2  Have there been any studies of adults or child...  ['askADHD', 'ADHD']  \n",
       "3  Environmental factors don‚Äôt directly cause ADH...                  NaN  \n",
       "4  Here in Spain we celebrate the national day of...             ['ADHD']  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b16a375",
   "metadata": {},
   "source": [
    "**Data Cleaning**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403985ae",
   "metadata": {},
   "source": [
    "1. Remove links\n",
    "2. Remove '@' and usernames\n",
    "3. Remove retweets\n",
    "4. Remove english words that do not contribute to the meaning of the sentence (and, or, while, especially, etc.)\n",
    "5. Remove words that appear in almost every tweet ('adhd', 'add', etc.)\n",
    "6. Remove punctuation\n",
    "7. Remove double-spacing\n",
    "8. Remove numbers\n",
    "9. Keep the stem of the words (i.e awareness, aware, - will all be recognized as 'awar')\n",
    "10. Check for words that appear together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5fd25d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### data cleaning ###\n",
    "def remove_links(tweet):\n",
    "    '''Takes a string and removes web links from it'''\n",
    "    tweet = re.sub(r'http\\S+', '', tweet) # remove http links\n",
    "    tweet = re.sub(r'bit.ly/\\S+', '', tweet) # rempve bitly links\n",
    "    tweet = tweet.strip('[link]') # remove [links]\n",
    "    return tweet\n",
    "\n",
    "def remove_users(tweet):\n",
    "    '''Takes a string and removes retweet and @user information'''\n",
    "    tweet = re.sub('(RT\\s@[A-Za-z]+[A-Za-z0-9-_]+)', '', tweet) # remove retweet\n",
    "    tweet = re.sub('(@[A-Za-z]+[A-Za-z0-9-_]+)', '', tweet) # remove tweeted at\n",
    "    tweet = re.sub ('#', '', tweet) # remove hashtags\n",
    "    return tweet\n",
    "\n",
    "def remove_emojis(tweet):\n",
    "    emoj = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u\"\\U00010000-\\U0010ffff\"\n",
    "        u\"\\u2640-\\u2642\" \n",
    "        u\"\\u2600-\\u2B55\"\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u23cf\"\n",
    "        u\"\\u23e9\"\n",
    "        u\"\\u231a\"\n",
    "        u\"\\ufe0f\"  # dingbats\n",
    "        u\"\\u3030\"\n",
    "                      \"]+\", re.UNICODE)\n",
    "    return re.sub(emoj, '', tweet)\n",
    "my_stopwords = nltk.corpus.stopwords.words('english')\n",
    "repeated_words = ['ever', 'start', 'pre', '&amp', 'amp', \n",
    "                  'add', 'adhd', 'may', 'heard', 'know', \n",
    "                  'often', 'would','end', 'might', 'xd', \n",
    "                  'go', 'wait', 'especially', 'part',\n",
    "                  'current', 'entire', 'think', 'never',\n",
    "                 'listen']\n",
    "for i in repeated_words:\n",
    "    my_stopwords.append(i)\n",
    "word_rooter = nltk.stem.snowball.PorterStemmer(ignore_stopwords=False).stem\n",
    "my_punctuation = '!\"$%&\\'()*+,-./:;<=>?[\\\\]^_`‚Äô{|}~‚Ä¢@'\n",
    "\n",
    "# cleaning master function\n",
    "def clean_tweet(tweet, bigrams=False):\n",
    "    tweet = remove_users(tweet)\n",
    "    tweet = remove_links(tweet)\n",
    "    tweet = tweet.lower() # lower case\n",
    "    tweet = re.sub('['+my_punctuation + ']+', ' ', tweet) # strip punctuation\n",
    "    tweet = re.sub('\\s+', ' ', tweet) #remove double spacing\n",
    "    tweet = re.sub('([0-9]+)', '', tweet) # remove numbers\n",
    "    tweet = remove_emojis(tweet)\n",
    "    tweet_token_list = [word for word in tweet.split(' ')\n",
    "                            if word not in my_stopwords] # remove stopwords\n",
    "\n",
    "    tweet_token_list = [word_rooter(word) if '#' not in word else word\n",
    "                        for word in tweet_token_list] # apply word rooter\n",
    "    if bigrams:\n",
    "        tweet_token_list = tweet_token_list+[tweet_token_list[i]+'_'+tweet_token_list[i+1]\n",
    "                                            for i in range(len(tweet_token_list)-1)]\n",
    "    tweet = ' '.join(tweet_token_list)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b2754f",
   "metadata": {},
   "source": [
    "Save the original tweets + the cleaned up tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f50f37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['clean_tweet'] = data.text.apply(clean_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "505669ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=\"Unnamed: 0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadbacc7",
   "metadata": {},
   "source": [
    "Turn words into vectors to allow machine process algorithms to process it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4c7676e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Vectorize ###\n",
    "\n",
    "# the vectorizer object will be used to transform text to vector form\n",
    "vectorizer = CountVectorizer(max_df=0.9, min_df=25, token_pattern='\\w+|\\$[\\d\\.]+|\\S+')\n",
    "\n",
    "# apply transformation\n",
    "tf = vectorizer.fit_transform(data['clean_tweet']).toarray()\n",
    "\n",
    "# tf_feature_names tells us what word each column in the matric represents\n",
    "tf_feature_names = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3bc18f",
   "metadata": {},
   "source": [
    "Apply the machine learning algorithm (NMF) to find the main 5 topics in all tweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81b38afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\almag\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py:315: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  \"'nndsvda' in 1.1 (renaming of 0.26).\"), FutureWarning)\n",
      "C:\\Users\\almag\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py:1091: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  \" improve convergence.\" % max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NMF(alpha=0.1, l1_ratio=0.5, n_components=5, random_state=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Apply NMF topic modeling ###\n",
    "number_of_topics = 5\n",
    "model_nmf = NMF(n_components=number_of_topics, random_state=0, alpha=.1, l1_ratio=.5)\n",
    "model_nmf.fit(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9c540cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### show topic modeling ###\n",
    "def display_topics(model, feature_names, no_top_words):\n",
    "    topic_dict = {}\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        topic_dict[\"Topic %d words\" % (topic_idx)]= ['{}'.format(feature_names[i])\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]\n",
    "        # topic_dict[\"Topic %d weights\" % (topic_idx)]= ['{:.1f}'.format(topic[i])\n",
    "                        # for i in topic.argsort()[:-no_top_words - 1:-1]]\n",
    "    return pd.DataFrame(topic_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a0267e",
   "metadata": {},
   "source": [
    "Show what words appear most often in the 5 classified topics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51c5998a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic 0 words</th>\n",
       "      <th>Topic 1 words</th>\n",
       "      <th>Topic 2 words</th>\n",
       "      <th>Topic 3 words</th>\n",
       "      <th>Topic 4 words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>parent</td>\n",
       "      <td>brain</td>\n",
       "      <td>diagnosi</td>\n",
       "      <td>feel</td>\n",
       "      <td>planner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sleep</td>\n",
       "      <td>learn</td>\n",
       "      <td>women</td>\n",
       "      <td>life</td>\n",
       "      <td>adhdawarenessmonth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>import</td>\n",
       "      <td>adhdawar</td>\n",
       "      <td>decad</td>\n",
       "      <td>diagnos</td>\n",
       "      <td>adhdtwitt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>find</td>\n",
       "      <td>meet</td>\n",
       "      <td>childhood</td>\n",
       "      <td>thank</td>\n",
       "      <td>mani</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ask</td>\n",
       "      <td>teamadhd</td>\n",
       "      <td>disord</td>\n",
       "      <td>listen</td>\n",
       "      <td>adhdawar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>chang</td>\n",
       "      <td>frontal</td>\n",
       "      <td>sign</td>\n",
       "      <td>current</td>\n",
       "      <td>go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>question</td>\n",
       "      <td>lifeinadhd</td>\n",
       "      <td>neurodevelopment</td>\n",
       "      <td>valid</td>\n",
       "      <td>differ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>exercis</td>\n",
       "      <td>vortex</td>\n",
       "      <td>treatment</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>adhdperson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>start</td>\n",
       "      <td>help</td>\n",
       "      <td>option</td>\n",
       "      <td>contributor</td>\n",
       "      <td>start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>matter</td>\n",
       "      <td>disord</td>\n",
       "      <td>persist</td>\n",
       "      <td>bawl</td>\n",
       "      <td>alreadi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Topic 0 words Topic 1 words     Topic 2 words Topic 3 words  \\\n",
       "0        parent         brain          diagnosi          feel   \n",
       "1         sleep         learn             women          life   \n",
       "2        import      adhdawar             decad       diagnos   \n",
       "3          find          meet         childhood         thank   \n",
       "4           ask      teamadhd            disord        listen   \n",
       "5         chang       frontal              sign       current   \n",
       "6      question    lifeinadhd  neurodevelopment         valid   \n",
       "7       exercis        vortex         treatment       kitchen   \n",
       "8         start          help            option   contributor   \n",
       "9        matter        disord           persist          bawl   \n",
       "\n",
       "        Topic 4 words  \n",
       "0             planner  \n",
       "1  adhdawarenessmonth  \n",
       "2           adhdtwitt  \n",
       "3                mani  \n",
       "4            adhdawar  \n",
       "5                  go  \n",
       "6              differ  \n",
       "7          adhdperson  \n",
       "8               start  \n",
       "9             alreadi  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_top_words =  10\n",
    "display_topics(model_nmf, tf_feature_names, no_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac68da2",
   "metadata": {},
   "source": [
    "From here, we infer the name of the topic/category based on the 7 most frequent words that the algorithm has identified."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ae81c2",
   "metadata": {},
   "source": [
    "- **Topic 0 (Lifestyle/Factors)**: Given its most frequent words, like import (most likely a root for the word important), exercise, sleep, change, etc., it seems to be describing the contributing factors that we can change, or that impact ADHD. \n",
    "- **Topic 1 (Scientific Explanation)**: Given the words like brain, learn, frontal, etc., this topic seems to be describing the scientific explanations for ADHD.\n",
    "- **Topic 2 (Diagnosis)**: Given the words like diagnosis, sign, neurodevelopment, etc., this topic seems to be describing the diagnosis of ADHD.\n",
    "- **Topic 3 (Experience)**: Given the words like feel, current, thank, etc., this topic seems to be describing the momentarily.\n",
    "- **Topic 4 (Awareness)**: This topic seems to be gathering a lot of awareness keywords, which we will categorize as simply 'awareness'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4deb3633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# category 0: Lifestyle/Factors\n",
    "# category 1: Scientific Explanation\n",
    "# category 2: Diagnosis\n",
    "# category 3: Experience\n",
    "# category 4: Awareness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7a363f",
   "metadata": {},
   "source": [
    "We add the labels of the topics in our original data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "964b3724",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_topic = model_nmf.transform(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d934302",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_name = ['Lifestyle/Factors', 'Scientific Explanation', 'Diagnosis', 'Experience', 'Awareness']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1858817",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = []\n",
    "categories = []\n",
    "for n in range(doc_topic.shape[0]):\n",
    "    topic_doc = doc_topic[n].argmax()\n",
    "    classes.append(topic_doc)\n",
    "    categories.append(cat_name[topic_doc])\n",
    "    # print(\"Document\", n+1, \"Topic\", topic_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76edda3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['category'] = categories\n",
    "data['class'] = classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0cce770e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_description</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>category</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>‚ù§Sal / UK\\r\\r\\nüß°Player of games, Master of non...</td>\n",
       "      <td>Saw GP today and we went through stuff and I t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>saw gp today went stuff tick box send referr t...</td>\n",
       "      <td>Diagnosis</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27y/o nonbinary creator. They/Them. disabled. ...</td>\n",
       "      <td>My ADHD Graveyard | Officially Diagnosed and A...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>graveyard offici diagnos hobbi adhdawarenessmo...</td>\n",
       "      <td>Awareness</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38. A diagnosis referral is hard in the UK. Se...</td>\n",
       "      <td>Have there been any studies of adults or child...</td>\n",
       "      <td>['askADHD', 'ADHD']</td>\n",
       "      <td>studi adult children particip team sport work ...</td>\n",
       "      <td>Awareness</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OrganizeU4Life is making an impact on the live...</td>\n",
       "      <td>Environmental factors don‚Äôt directly cause ADH...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>environment factor directli caus least natur a...</td>\n",
       "      <td>Awareness</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>üîû. Mainly NSFW. He/Him. 28. Gay, Single and Lo...</td>\n",
       "      <td>Here in Spain we celebrate the national day of...</td>\n",
       "      <td>['ADHD']</td>\n",
       "      <td>spain celebr nation day peopl bad moment wish ...</td>\n",
       "      <td>Awareness</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    user_description  \\\n",
       "0  ‚ù§Sal / UK\\r\\r\\nüß°Player of games, Master of non...   \n",
       "1  27y/o nonbinary creator. They/Them. disabled. ...   \n",
       "2  38. A diagnosis referral is hard in the UK. Se...   \n",
       "3  OrganizeU4Life is making an impact on the live...   \n",
       "4  üîû. Mainly NSFW. He/Him. 28. Gay, Single and Lo...   \n",
       "\n",
       "                                                text             hashtags  \\\n",
       "0  Saw GP today and we went through stuff and I t...                  NaN   \n",
       "1  My ADHD Graveyard | Officially Diagnosed and A...                  NaN   \n",
       "2  Have there been any studies of adults or child...  ['askADHD', 'ADHD']   \n",
       "3  Environmental factors don‚Äôt directly cause ADH...                  NaN   \n",
       "4  Here in Spain we celebrate the national day of...             ['ADHD']   \n",
       "\n",
       "                                         clean_tweet   category  class  \n",
       "0  saw gp today went stuff tick box send referr t...  Diagnosis      2  \n",
       "1  graveyard offici diagnos hobbi adhdawarenessmo...  Awareness      4  \n",
       "2  studi adult children particip team sport work ...  Awareness      4  \n",
       "3  environment factor directli caus least natur a...  Awareness      4  \n",
       "4  spain celebr nation day peopl bad moment wish ...  Awareness      4  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['user_description', 'text', 'hashtags', 'clean_tweet', 'category', 'class']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a41250",
   "metadata": {},
   "source": [
    "**An example of Categorization in topics**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8dc713",
   "metadata": {},
   "source": [
    "We select a random tweet: namely, tweet 444."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9d987c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Really interesting discussion today. But very obvious that so much more needs to be done to raise awareness of #ADHD and the devastating effects it can have on people's Iives. Thank you @ADHDFoundation &amp; @djohnsonmsp https://t.co/SKZPY7KNXj\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'][444]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0d579b",
   "metadata": {},
   "source": [
    "Its category has been selected as Awareness, which seems to be adequate given the tweet content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b219641a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Awareness'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['category'][444]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

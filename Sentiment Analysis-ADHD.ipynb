{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "710be52d",
   "metadata": {},
   "source": [
    "# NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768a12cf",
   "metadata": {},
   "source": [
    "### In this part we train our machine learning algorithm to recognize positive and negative sentiments:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef17df6a",
   "metadata": {},
   "source": [
    "https://www.datacamp.com/community/tutorials/text-analytics-beginners-nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e550cf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import random as random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3205c2e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @ScottWalker: Didn't catch the full #GOPdeb...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @RobGeorge: That Carly Fiorina is trending ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @DanScavino: #GOPDebate w/ @realDonaldTrump...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RT @GregAbbott_TX: @TedCruz: \"On my first day ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RT @warriorwoman91: I liked her and was happy ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment\n",
       "1  RT @ScottWalker: Didn't catch the full #GOPdeb...  Positive\n",
       "3  RT @RobGeorge: That Carly Fiorina is trending ...  Positive\n",
       "4  RT @DanScavino: #GOPDebate w/ @realDonaldTrump...  Positive\n",
       "5  RT @GregAbbott_TX: @TedCruz: \"On my first day ...  Positive\n",
       "6  RT @warriorwoman91: I liked her and was happy ...  Negative"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training data\n",
    "data = pd.read_csv('Sentiment.csv')\n",
    "data = data[['text', 'sentiment']]\n",
    "data = data[data.sentiment != \"Neutral\"]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d56cd9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative Sentiment count: 8493\n",
      "Positive Sentiment count: 2236\n"
     ]
    }
   ],
   "source": [
    "# imbalanced dataset\n",
    "print('Negative Sentiment count:', len(data[data['sentiment']=='Negative']))\n",
    "print('Positive Sentiment count:',len(data[data['sentiment']=='Positive']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2334d81f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative Sentiment count: 2236\n",
      "Positive Sentiment count: 2236\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @BrianZahnd: My Native American friends get...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @ergeekgoddess: Yo #GOPDebate, I'm really h...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Each #GOPdebate should be staged with one chai...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Babara Boxer running a CHECK on Carly Fiorina ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @HillaryClinton: Watch the #GOPdebate? Bet ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment\n",
       "0  RT @BrianZahnd: My Native American friends get...  Negative\n",
       "1  RT @ergeekgoddess: Yo #GOPDebate, I'm really h...  Negative\n",
       "2  Each #GOPdebate should be staged with one chai...  Negative\n",
       "3  Babara Boxer running a CHECK on Carly Fiorina ...  Positive\n",
       "4  RT @HillaryClinton: Watch the #GOPdebate? Bet ...  Negative"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# undersample\n",
    "positive_df = data[data.sentiment != \"Negative\"]\n",
    "negative_df = data[data.sentiment == \"Negative\"]\n",
    "\n",
    "negative_df = negative_df[:len(positive_df)]\n",
    "\n",
    "print('Negative Sentiment count:', len(negative_df))\n",
    "print('Positive Sentiment count:', len(positive_df))\n",
    "\n",
    "# concat the balanced data\n",
    "balanced_data = pd.concat([negative_df, positive_df])\n",
    "balanced_data = balanced_data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "balanced_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46e67fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer to remove unwanted elements from out data like symbols and numbers\n",
    "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
    "\n",
    "# create a sparse matrix (BoW)\n",
    "tf=TfidfVectorizer(lowercase=True,stop_words='english',ngram_range = (1,1),tokenizer = token.tokenize)\n",
    "text_tf= tf.fit_transform(balanced_data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b06a1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(text_tf, balanced_data['sentiment'], test_size=0.1, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8cf2d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB Classifier Accuracy: 0.7901785714285714\n"
     ]
    }
   ],
   "source": [
    "# classify\n",
    "\n",
    "clf = MultinomialNB(alpha=0.1).fit(X_train, y_train)\n",
    "predicted= clf.predict(X_test)\n",
    "\n",
    "print(\"MultinomialNB Classifier Accuracy:\",metrics.accuracy_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9609e094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Negative'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test for the first element\n",
    "text_tf_2 = tf.fit_transform(balanced_data['text'])\n",
    "clf.predict(text_tf_2)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95cb956",
   "metadata": {},
   "source": [
    "### Here, we input our own data, we clean it and we classify each tweet as positive or negative:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0807ced2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('adhd.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "462990d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "### data cleaning ###\n",
    "def remove_links(tweet):\n",
    "    '''Takes a string and removes web links from it'''\n",
    "    tweet = re.sub(r'http\\S+', '', tweet) # remove http links\n",
    "    tweet = re.sub(r'bit.ly/\\S+', '', tweet) # rempve bitly links\n",
    "    tweet = tweet.strip('[link]') # remove [links]\n",
    "    return tweet\n",
    "\n",
    "def remove_users(tweet):\n",
    "    '''Takes a string and removes retweet and @user information'''\n",
    "    tweet = re.sub('(RT\\s@[A-Za-z]+[A-Za-z0-9-_]+)', '', tweet) # remove retweet\n",
    "    tweet = re.sub('(@[A-Za-z]+[A-Za-z0-9-_]+)', '', tweet) # remove tweeted at\n",
    "    return tweet\n",
    "\n",
    "my_stopwords = nltk.corpus.stopwords.words('english')\n",
    "word_rooter = nltk.stem.snowball.PorterStemmer(ignore_stopwords=False).stem\n",
    "my_punctuation = '!\"$%&\\'()*+,-./:;<=>?[\\\\]^_`{|}~•@'\n",
    "\n",
    "# cleaning master function\n",
    "def clean_tweet(tweet, bigrams=False):\n",
    "    tweet = remove_users(tweet)\n",
    "    tweet = remove_links(tweet)\n",
    "    tweet = tweet.lower() # lower case\n",
    "    tweet = re.sub('['+my_punctuation + ']+', ' ', tweet) # strip punctuation\n",
    "    tweet = re.sub('\\s+', ' ', tweet) #remove double spacing\n",
    "    tweet = re.sub('([0-9]+)', '', tweet) # remove numbers\n",
    "    tweet_token_list = [word for word in tweet.split(' ')\n",
    "                            if word not in my_stopwords] # remove stopwords\n",
    "\n",
    "    tweet_token_list = [word_rooter(word) if '#' not in word else word\n",
    "                        for word in tweet_token_list] # apply word rooter\n",
    "    if bigrams:\n",
    "        tweet_token_list = tweet_token_list+[tweet_token_list[i]+'_'+tweet_token_list[i+1]\n",
    "                                            for i in range(len(tweet_token_list)-1)]\n",
    "    tweet = ' '.join(tweet_token_list)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26bcd1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "data['clean_tweet'] = data.text.apply(clean_tweet, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7bedee4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    saw gp today went stuff tick box adhd send ref...\n",
       "1    adhd graveyard offici diagnos hobbi #adhdaware...\n",
       "2    studi adult children adhd particip team sport ...\n",
       "3    environment factor don’t directli caus adhd le...\n",
       "4    spain celebr nation day peopl #adhd never bad ...\n",
       "Name: clean_tweet, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = data['clean_tweet']\n",
    "tweets.dropna(how='all')\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3100e0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the actual data\n",
    "tweet_tf= tf.transform(tweets.values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f469ca14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classify\n",
    "sentiment = []\n",
    "for i in range(len(list(tweets))):\n",
    "    s = clf.predict(tweet_tf)[i]\n",
    "    sentiment.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e8183d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add sentiment to the dataset\n",
    "data['sentiment'] = sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498e78d0",
   "metadata": {},
   "source": [
    "\n",
    "### Sentiment Analysis done!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3b7b6f",
   "metadata": {},
   "source": [
    "### Let's test a random tweet, namely 567:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "909eee1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Gender bias is leaving many #women with attention deficit hyperactivity disorder undiagnosed (#ADHD), leading psychologists are warning. BBC News https://t.co/M6GcVUa8ih'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.text[567]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180b2ce0",
   "metadata": {},
   "source": [
    "### The algorithm outputs 'negative', which seems right:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43adb424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Negative'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sentiment[567]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd815cd",
   "metadata": {},
   "source": [
    "### The algorithm has classified 2,777 tweets as 'Positive' and 8,025 'Negative'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a3a8b5",
   "metadata": {},
   "source": [
    "That means roughly 26% of the tweets about depression on Twitter are positive, and 74% are of negative sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f3e7dad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2777"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[data['sentiment']=='Positive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d1e29bd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8025"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[data['sentiment']=='Negative'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "195a2855",
   "metadata": {},
   "source": [
    "# NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040ec2f9",
   "metadata": {},
   "source": [
    "### In this part we train our machine learning algorithm to recognize positive and negative sentiments:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db8933e",
   "metadata": {},
   "source": [
    "https://www.datacamp.com/community/tutorials/text-analytics-beginners-nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e444a2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import random as random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dba4f156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @ScottWalker: Didn't catch the full #GOPdeb...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @RobGeorge: That Carly Fiorina is trending ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @DanScavino: #GOPDebate w/ @realDonaldTrump...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RT @GregAbbott_TX: @TedCruz: \"On my first day ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RT @warriorwoman91: I liked her and was happy ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment\n",
       "1  RT @ScottWalker: Didn't catch the full #GOPdeb...  Positive\n",
       "3  RT @RobGeorge: That Carly Fiorina is trending ...  Positive\n",
       "4  RT @DanScavino: #GOPDebate w/ @realDonaldTrump...  Positive\n",
       "5  RT @GregAbbott_TX: @TedCruz: \"On my first day ...  Positive\n",
       "6  RT @warriorwoman91: I liked her and was happy ...  Negative"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training data\n",
    "data = pd.read_csv('Sentiment.csv')\n",
    "data = data[['text', 'sentiment']]\n",
    "data = data[data.sentiment != \"Neutral\"]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0adce29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative Sentiment count: 8493\n",
      "Positive Sentiment count: 2236\n"
     ]
    }
   ],
   "source": [
    "# imbalanced dataset\n",
    "print('Negative Sentiment count:', len(data[data['sentiment']=='Negative']))\n",
    "print('Positive Sentiment count:',len(data[data['sentiment']=='Positive']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a7dfc5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative Sentiment count: 2236\n",
      "Positive Sentiment count: 2236\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"@FoxNews web stream and mobile app fail durin...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hahahahah this commentary is the best. #GOPDeb...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @Reince: Simply incredible. http://t.co/apX...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @TheRighToExist: Wow!! She is good!! Watch ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @RWSurferGirl: Ask Trump a legitimate quest...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment\n",
       "0  \"@FoxNews web stream and mobile app fail durin...  Negative\n",
       "1  Hahahahah this commentary is the best. #GOPDeb...  Positive\n",
       "2  RT @Reince: Simply incredible. http://t.co/apX...  Positive\n",
       "3  RT @TheRighToExist: Wow!! She is good!! Watch ...  Positive\n",
       "4  RT @RWSurferGirl: Ask Trump a legitimate quest...  Positive"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# undersample\n",
    "positive_df = data[data.sentiment != \"Negative\"]\n",
    "negative_df = data[data.sentiment == \"Negative\"]\n",
    "\n",
    "negative_df = negative_df[:len(positive_df)]\n",
    "\n",
    "print('Negative Sentiment count:', len(negative_df))\n",
    "print('Positive Sentiment count:', len(positive_df))\n",
    "\n",
    "# concat the balanced data\n",
    "balanced_data = pd.concat([negative_df, positive_df])\n",
    "balanced_data = balanced_data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "balanced_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e17d711b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer to remove unwanted elements from out data like symbols and numbers\n",
    "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
    "\n",
    "# create a sparse matrix (BoW)\n",
    "tf=TfidfVectorizer(lowercase=True,stop_words='english',ngram_range = (1,1),tokenizer = token.tokenize)\n",
    "text_tf= tf.fit_transform(balanced_data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b86ec666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(text_tf, balanced_data['sentiment'], test_size=0.1, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d21059f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB Classifier Accuracy: 0.8080357142857143\n"
     ]
    }
   ],
   "source": [
    "# classify\n",
    "\n",
    "clf = MultinomialNB(alpha=0.1).fit(X_train, y_train)\n",
    "predicted= clf.predict(X_test)\n",
    "\n",
    "print(\"MultinomialNB Classifier Accuracy:\",metrics.accuracy_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbfe2cbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Negative'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test for the first element\n",
    "text_tf_2 = tf.fit_transform(balanced_data['text'])\n",
    "clf.predict(text_tf_2)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592886fa",
   "metadata": {},
   "source": [
    "### Here, we input our own data, we clean it and we classify each tweet as positive or negative:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4eb45c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('ocd.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0fbfcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "### data cleaning ###\n",
    "def remove_links(tweet):\n",
    "    '''Takes a string and removes web links from it'''\n",
    "    tweet = re.sub(r'http\\S+', '', tweet) # remove http links\n",
    "    tweet = re.sub(r'bit.ly/\\S+', '', tweet) # rempve bitly links\n",
    "    tweet = tweet.strip('[link]') # remove [links]\n",
    "    return tweet\n",
    "\n",
    "def remove_users(tweet):\n",
    "    '''Takes a string and removes retweet and @user information'''\n",
    "    tweet = re.sub('(RT\\s@[A-Za-z]+[A-Za-z0-9-_]+)', '', tweet) # remove retweet\n",
    "    tweet = re.sub('(@[A-Za-z]+[A-Za-z0-9-_]+)', '', tweet) # remove tweeted at\n",
    "    return tweet\n",
    "\n",
    "my_stopwords = nltk.corpus.stopwords.words('english')\n",
    "word_rooter = nltk.stem.snowball.PorterStemmer(ignore_stopwords=False).stem\n",
    "my_punctuation = '!\"$%&\\'()*+,-./:;<=>?[\\\\]^_`{|}~â€¢@'\n",
    "\n",
    "# cleaning master function\n",
    "def clean_tweet(tweet, bigrams=False):\n",
    "    tweet = remove_users(tweet)\n",
    "    tweet = remove_links(tweet)\n",
    "    tweet = tweet.lower() # lower case\n",
    "    tweet = re.sub('['+my_punctuation + ']+', ' ', tweet) # strip punctuation\n",
    "    tweet = re.sub('\\s+', ' ', tweet) #remove double spacing\n",
    "    tweet = re.sub('([0-9]+)', '', tweet) # remove numbers\n",
    "    tweet_token_list = [word for word in tweet.split(' ')\n",
    "                            if word not in my_stopwords] # remove stopwords\n",
    "\n",
    "    tweet_token_list = [word_rooter(word) if '#' not in word else word\n",
    "                        for word in tweet_token_list] # apply word rooter\n",
    "    if bigrams:\n",
    "        tweet_token_list = tweet_token_list+[tweet_token_list[i]+'_'+tweet_token_list[i+1]\n",
    "                                            for i in range(len(tweet_token_list)-1)]\n",
    "    tweet = ' '.join(tweet_token_list)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "975d114f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "data['clean_tweet'] = data.text.apply(clean_tweet, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94f8aab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    new research find #acupuncture reduc #depressi...\n",
       "1    new research find #acupuncture reduc #depressi...\n",
       "2    new research find #acupuncture reduc #depressi...\n",
       "3    new research find #acupuncture reduc #depressi...\n",
       "4    new research find #acupuncture reduc #depressi...\n",
       "Name: clean_tweet, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = data['clean_tweet']\n",
    "tweets.dropna(how='all')\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5c029c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the actual data\n",
    "tweet_tf= tf.transform(tweets.values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc51cdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classify\n",
    "sentiment = []\n",
    "for i in range(len(list(tweets))):\n",
    "    s = clf.predict(tweet_tf)[i]\n",
    "    sentiment.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3e8e7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add sentiment to the dataset\n",
    "data['sentiment'] = sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e538abe6",
   "metadata": {},
   "source": [
    "\n",
    "### Sentiment Analysis done!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67210c0e",
   "metadata": {},
   "source": [
    "### Let's test a random tweet, namely 650:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e811d8db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Does anyone else write a to do list for the day ahead? ðŸ˜‚ helps me soooooo much , #adulting #ocd #beyou ðŸ¤”ðŸ˜‚'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.text[650]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f080b58b",
   "metadata": {},
   "source": [
    "### The algorithm outputs 'negative', which seems right:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79a973bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Positive'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sentiment[650]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd1b353",
   "metadata": {},
   "source": [
    "### The algorithm has classified 819 tweets as 'Positive' and 2,044 'Negative'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8c6c88",
   "metadata": {},
   "source": [
    "That means roughly 28% of the tweets about depression on Twitter are positive, and 72% are of negative sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4fe2652d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "819"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[data['sentiment']=='Positive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "adf499a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2044"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[data['sentiment']=='Negative'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
